# A Few Useful Things to Know about Machine Learning; Domingos, Pedro M., 2012

## [Article](https://dl.acm.org/doi/10.1145/2347736.2347755); Tags: #machine-learning #feature-engineering

> *Note* This is an excellent paper to summarize foundational topics in ML.

### Abridged Summary
This paper provides a few useful things to know about machine learning—ha ha! Machine Learning, specifically supervised learning, can be defined as the task of finding patterns in the training examples and inferring a function that represents the data. **A hypothesis is an approximation of the target function f : x -> f(x).** There can be multiple such functions, meaning a collection of hypotheses.

The author summarized the three components of machine learning algorithms as: 
> *LEARNING = REPRESENTATION + EVALUATION + OPTIMIZATION*.

Representation — A classifier must be represented by a formal language for a computer to handle. **Choosing a representation for a learner is tantamount to choosing the set of classifiers it can possibly learn.** We can formalize the idea of concept learning by referring to this set as the hypothesis space of the learner. 

The **hypothesis space** is the set of possible approximations that an algorithm can create for f to minimize loss. The choice of the algorithm (e.g., Neural Networks) and the configuration (e.g., adaptive learning rate) define the [infinite] hypothesis space that the eventual model may represent. Learning for an algorithm is defined as searching through the pre-defined space and evaluating for a candidate hypothesis that performs well, beyond the  the training examples. 

> **_H_** = {h<sub>1</sub>, h<sub>2</sub>, ..., h<sub>*n*</sub>}

That is to say if a model is not in the hypothesis space, it simply cannot be learned. A **model** is defined as a mathematical representation that employs a hypothesis (e.g., a probabilistic model is used in n-grams based off the statistics of the document/collection). A hypothesis becomes a model after evaluation has been done and results are favorable. Remember, we do not want "Logistic Regression" in the abstract sense but rather the model that comes from training the algorithm.

Here we have the choice (i.e., choosing the representation) whether to restrict our hypothesis space or extend our hypothesis space to more complex algorithms. The hypothesis set is contrained by the choice of framing problem, the model we choose and its configuration. 

> *Note* The choice of algorithm and configuration involves the assumption that a hypothesis space is believed to contain the true hypothesis or the best apporoximation of the target function. In practice, this is very challenging, and it is often more efficient to employ a range of different hypothesis spaces. 

Evaluation — the evaluation function, also *objective function* in the literature, allows us to distinguish good classifiers from bad classifiers. 

Optimization — pending...

## Generalization
Once a hypothesis is formulated and evaluated, the fundamental goal is to test the model's capability to generalize beyond the test examples.
