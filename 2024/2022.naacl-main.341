# Symbolic Knowledge Distillation: from General Language Models to Commonsense Models; West et al, 2022

## [Paper]https://aclanthology.org/2022.naacl-main.341/); Tags: #nlp #symbolic-knowledge # common-sense

### Introduction
To train a language model for common-sense knowledge, a common practice had humans author a knowledge graph for training non-common sense models. The process of symbolic knowledge distillation In order to test sym 
