# Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging; 1995

## [Full Paper](https://aclanthology.org/J95-4004/); Tags: #part-of-speech-tagging #transformation-based #error-driven-learning 

### Summary
1. A transformation-based approach obtains competitive performance to corpus-based techniques.
2. Easily portable and readable (example of explainable AI).
3. 2 types of taggers: nonlexicalized tagger, lexicalized tagger.
4. Rewrite rules may contribute the more errors.

### The Approach

1. Annotated text is passed through an initial-state annotator. The initial-state annotators can vary in complex, ranging from labelling all words as nouns; labelling all words with their most common pos tag; and the stochastic n-gram tagger.
2. The text is evaluated by the initial-state, then it is compared to the ground truth labels from the corpus.
3. An ordered list of transformations is to be *learned* whose output **most** closely align to the truth. The transformation is found according to the best score (greatest error reduction) during each learning iteration over the training set. This is done in a cascade fashion, where the result of the transformations is used for the next iteration, and so (labelled Tn for transformation phase).
4. Next the patch corpus is evaluated based off these transformations.

In a transformation-based tagger, the lexicon is the list of all possible tags seen from the data, with one tag labelled as most likely. Interestingly, the lexicalized version doesn't significantly improve upon the baseline 

### Final notes
